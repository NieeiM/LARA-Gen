This repo is demo page of LARA-Gen paper. Your listen to the generated samples on https://nieeim.github.io/LARA-Gen/.
Paper: https://arxiv.org/abs/2510.05875

# Abstract

Recent advances in text-to-music models have enabled coherent music generation from text prompt, yet fine-grained emotional control remains unresolved. We introduce LARA-Gen, a framework for continuous emotion control that aligns the internal hidden states with external music understanding model through Latent Affective Representation Alignment (LARA), enabling effective training.In addition, we design an emotion control module based on a continuous valence-arousal space, disentangling emotional attributes from textual content and bypassing the bottlenecks of text-based prompting.Furthermore, we establish a benchmark with a curated test set and a robust Emotion Predictor, facilitating objective evaluation of emotional controllability in music generation.Extensive experiments demonstrate that LARA-Gen achieves continuous, fine-grained control of emotion and significantly outperforms baselines in both emotion adherence and music quality.

# Bibtex

```latex
@article{Mei2024LARAGen,
  title={LARA-Gen: Enabling Continuous Emotion Control for Music Generation Models via Latent Affective Representation Alignment},
  author={Jiahao Mei and Xuenan Xu and Zeyu Xie and Zihao Zheng and Ye Tao and Yue Ding and Mengyue Wu},
  journal={arxiv},
  year={2025},
  url={https://arxiv.org/abs/2510.05875}
}
```
